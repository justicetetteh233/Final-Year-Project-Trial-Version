{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfea3ccc-37dd-409f-a928-894b3dd33c51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"lets_start\")\n",
    "#import all the necessary libraries and tell why \n",
    "from utils.Configs import * #has the parameters for the various models\n",
    "from tensorflow.python.keras import backend as K\n",
    "#provides low-level operations for Keras models, such as: Tensor manipulations Mathematical operations Session management Device configuration (e.g., CPU/GPU selection) Memory handling\n",
    "\n",
    "from cnn.inputpipeline import InputProcessor\n",
    "from cnn.mammocnn import MammoCNN\n",
    "from utils.SavedResult import ProcessResult\n",
    "\n",
    "from cnn.binaryoptimzers import feature_optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0966f683-1a7d-4162-9162-5d2aca0adb24",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('medical image classification project started')\n",
    "print('we are going to train our model')\n",
    "# Taking the model to handle our mammogram images \n",
    "\n",
    "#we need to define the various hyperparameters and optimizers for our model which has to deduce the feature set from an image.\n",
    "# opt, lr = optimizers[1], learning_rates[6], #we obtain this from our configuration file  = 1:\"Adam\",  6:1e-06\n",
    "\n",
    "\n",
    "# this is the optimization algorithm and learning rates we want to use for the model traning process  Adam , 1e-06\n",
    "\n",
    "#start data reading process\n",
    "\n",
    "#define an object to show the mammogramme data \n",
    "    #Load mammo mias datasets\n",
    "print(\"this is the dataset features and the split we will like to use \")\n",
    "\n",
    "data_params={\n",
    "        'num_classes':len(mammo_mias_classes), 'class_names':mammo_mias_classes, \n",
    "        'input_dataset':mias_input_dataset, 'testing_dataset':mias_input_dataset,\n",
    "        'img_size':mammo_img_size,  'num_channels':mammo_num_channels,\n",
    "        'train_split':train_split, 'test_split':test_split, 'eval_split':eval_split,\n",
    "        'train_using':train_using_mammo_mias, 'K':K\n",
    "        }\n",
    "\n",
    "print('this is the data parameters we will use for the model training process ',data_params)\n",
    "\n",
    "#this is the data parameters we will use for the model training process  {'num_classes': 5, 'class_names': {0: 'N', 1: 'BC', 2: 'BM', 3: 'CALC', 4: 'M'}, 'input_dataset': './data/mias/', 'testing_dataset': './data/mias/', 'img_size': {'width': 299, 'height': 299}, 'num_channels': 1 (meaning one grayscale), 'train_split': 0.75, 'test_split': 0.15, 'eval_split': 0.1, 'train_using': 'mias', 'K': <module 'tensorflow.python.keras.backend' from '/home/justice/anaconda3/lib/python3.12/site-packages/tensorflow/python/keras/backend.py'>}\n",
    "\n",
    "print('now that we we have our images and splits lets process our input data')\n",
    "mammo_input_mias=InputProcessor(data_params=data_params) #this is actually a class which requires the given structure to construct what it takes to construct the model \n",
    "\n",
    "print('lets get our training data and splits from the image in the form of array images')\n",
    "mammo_input_mias.get_train_input() #why: this function is used to fetch the image data, convert it to arrays, convert it  GRAYSCALE, standarize it to fall with the interval of 0 to 1 and also use percentages define to construct the train, eval, and test data. but does not return anything it just does an internal job. thus a void method. to update the properties of the class Object made by the InputProcessor.\n",
    "\n",
    "#Todo 1:i have commented this out because am just using mias dataset.\n",
    "# repeat same for ddsm data\n",
    "#Load mammo ddsm datasets\n",
    "# data_params['num_classes']=len(mammo_ddsm_classes)\n",
    "# data_params['class_names']=mammo_ddsm_classes \n",
    "# data_params['input_dataset']=ddsm_input_dataset \n",
    "# data_params['testing_dataset']=ddsm_input_dataset            \n",
    "# data_params['train_using']=train_using_mammo_ddsm\n",
    "# mammo_input_ddsm=InputProcessor(data_params=data_params)\n",
    "# #mammo_input_ddsm.get_train_input()\n",
    "\n",
    "# if isCombineMammoDatasets:\n",
    "#     x, y=mammo_input_mias.get_train_data()\n",
    "#     mammo_input_ddsm.set_training_data(x, y)\n",
    "#     x, y=mammo_input_mias.get_eval_data()\n",
    "#     mammo_input_ddsm.set_eval_data(x, y)\n",
    "#     x, y=mammo_input_mias.get_test_data()\n",
    "#     mammo_input_ddsm.set_test_data(x, y)\n",
    "\n",
    "\n",
    "\n",
    "#End of data reading and processing\n",
    "\n",
    "    #Train MammoCNN\n",
    "'''\n",
    "Run1:optimizers[6], learning_rates[5]\n",
    "Run2:optimizers[5], learning_rates[5]\n",
    "Run3:optimizers[1], learning_rates[5]\n",
    "Run4:optimizers[1], learning_rates[4] \n",
    "'''\n",
    "\n",
    "opt, lr=optimizers[1], learning_rates[4]\n",
    "print('this is the optimization algorithm and learning rates we want to use to fetch the features of the images ',opt,lr)\n",
    "\n",
    "mamocnn_paras={\n",
    "    'learning_rates':lr,  'optimizers':opt, 'activations':activations[1], \n",
    "    'pooling':pooling[1], 'regularizers':regularizers[1], 'fcactivations':fcactivations[0], \n",
    "    'lossfunc':lossfunc[0], 'cnn_epoch':cnn_epoch, 'batch_size':batch_size,        \n",
    "    'log_mode':log_mode, 'models_path':models_path, 'model_filename':mammo_model_filename,\n",
    "    'save_results_dir':save_results_dir, 'show':show, 'K':K, \n",
    "    'checkpoint_epoch':40, 'fromCheckpoint':False, 'train_model': True,\n",
    "    \n",
    "    'num_classes':len(mammo_mias_classes), 'class_names':mammo_mias_classes, \n",
    "    'img_size':mammo_img_size, 'num_channels':mammo_num_channels, \n",
    "    'input_source':mammo_input_mias,\n",
    "    \"experiment\":\"mammocnn_eph{}_optz{}_lr{}\".format(cnn_epoch,opt,lr),\n",
    "    \"filename\":\"mammocnn_eph{}_optz{}_lr{}\".format(cnn_epoch,opt,lr),\n",
    "    'optimzed_result_file':\"optimized_mammo_eph{}_{}_lr{}\".format(cnn_epoch,opt,lr),\n",
    "    \n",
    "    'checkpoint_path':mammo_checkpoint_path, \"save_multimodal_results_dir\":save_mammo_results_dir,         \n",
    "}\n",
    "\n",
    "print('this is the parameters we will use for by the cnn to fetch features of various images from the image_array data associated with each  split ',mamocnn_paras)\n",
    "#this is the parameters we will use for the model training process  {'learning_rates': 0.0001, 'optimizers': 'Adam', 'activations': 'leakyrelu', 'pooling': 'Avg', 'regularizers': 'L2', 'fcactivations': 'softmax', 'lossfunc': 'categorical_crossentropy', 'cnn_epoch': 40, 'batch_size': 64, 'log_mode': 1, 'models_path': './outputs/models/', 'model_filename': 'trainedmodelmammo', 'save_results_dir': './outputs/results/', 'show': 1, 'K': <module 'tensorflow.python.keras.backend' from '/home/justice/anaconda3/lib/python3.12/site-packages/tensorflow/python/keras/backend.py'>, 'checkpoint_epoch': 40, 'fromCheckpoint': True, 'train_model': True, 'num_classes': 5, 'class_names': {0: 'N', 1: 'BC', 2: 'BM', 3: 'CALC', 4: 'M'}, 'img_size': {'width': 299, 'height': 299}, 'num_channels': 1, 'input_source': <cnn.inputpipeline.InputProcessor object at 0x79d3feb745c0>, 'experiment': 'mammocnn_eph40_optzAdam_lr0.0001', 'filename': 'mammocnn_eph40_optzAdam_lr0.0001', 'optimzed_result_file': 'optimized_mammo_eph40_Adam_lr0.0001', 'checkpoint_path': './outputs/checkpoints/mammo/', 'save_multimodal_results_dir': './outputs/results/training/mammo/'}\n",
    "\n",
    "\n",
    "mcnn=MammoCNN(mamocnn_paras=mamocnn_paras)\n",
    "mcnn.build_architecture()\n",
    "xtrain, ytrain=mammo_input_mias.get_training_data()\n",
    "xeval, yeval=mammo_input_mias.get_eval_data()\n",
    "x_test, y_test=mammo_input_mias.get_test_data()\n",
    "pr=ProcessResult(params=mamocnn_paras)\n",
    "\n",
    "if mamocnn_paras['train_model']:\n",
    "    if mamocnn_paras['fromCheckpoint']:\n",
    "        training_outcome=mcnn.load_trained_model(xtrain, ytrain, xeval, yeval)\n",
    "    else:\n",
    "        training_outcome=mcnn.trainmodel(mcnn.model, xtrain, ytrain, xeval, yeval)\n",
    "    \n",
    "     \n",
    "    #Predict with HistoCNN model\n",
    "    # prediction=mcnn.predict()\n",
    "    # pr.save_results(training_outcome, prediction)\n",
    "    \n",
    "    #Extract and optimize features from HistoCNN model\n",
    "    mcnn.extract_vector_features(mcnn.model, xtrain, ytrain, xeval, yeval, 'pool_4')\n",
    "\n",
    "\n",
    "# import numpy as np\n",
    "# import matplotlib.pyplot as plt\n",
    "# train_features = np.load(\"./outputs/checkpoints/mammo/train_features.npy\")\n",
    "# print(train_features)\n",
    "# print(\"Shape:\", train_features.shape)  # e.g., (1000, 8192)\n",
    "# plt.figure(figsize=(10, 4))\n",
    "# plt.plot(train_features[0])  # Plot first sample\n",
    "# plt.title(\"Feature Vector\")\n",
    "# plt.show()\n",
    "\n",
    "\n",
    "lb, ub, x, y, tx, ty=mcnn.optimize_vector_features(xtrain, ytrain, xeval, yeval)\n",
    "\n",
    "#Send features to binary optimizer for optimization process\n",
    "save_optimized_path=mamocnn_paras['checkpoint_path']\n",
    "#We are using the BEOSA method for the optimization, hence the selection of first binaryalgorithms[0]\n",
    "method = binaryalgorithms[0] #for method in binaryalgorithms:\n",
    "\n",
    "new_x_train, y_train=feature_optimizer(save_optimized_path, method, mcnn.model, x, y, tx, ty, modelrates, lb, ub, pr, mamocnn_paras['num_classes'], 'mammo', metrics_dir) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
